<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>爬虫 - 标签 - Joker-desire's Blog</title><link>https://Joker-desire.github.io/tags/%E7%88%AC%E8%99%AB/</link><description>爬虫 - 标签 - Joker-desire's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Fri, 24 Mar 2023 14:08:32 +0800</lastBuildDate><atom:link href="https://Joker-desire.github.io/tags/%E7%88%AC%E8%99%AB/" rel="self" type="application/rss+xml"/><item><title>使用Mixin模式配置Scrapy日志输出</title><link>https://Joker-desire.github.io/2023/03/%E4%BD%BF%E7%94%A8mixin%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AEscrapy%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/</link><pubDate>Fri, 24 Mar 2023 14:08:32 +0800</pubDate><author>Joker-desire</author><guid>https://Joker-desire.github.io/2023/03/%E4%BD%BF%E7%94%A8mixin%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AEscrapy%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/</guid><description>背景 为什么要重新配置Scrapy日志输出 在使用kafka进行处理爬虫数据后出现了一种现象：日志打印会将整个item数据打印出，由于使用kaf</description></item><item><title>Scrapy-Redis初始化数据处理</title><link>https://Joker-desire.github.io/2023/03/scrapy-redis%E5%88%9D%E5%A7%8B%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link><pubDate>Mon, 20 Mar 2023 10:13:49 +0800</pubDate><author>Joker-desire</author><guid>https://Joker-desire.github.io/2023/03/scrapy-redis%E5%88%9D%E5%A7%8B%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid><description>一、思考 在使用Scrapy-Redis进行数据初始化时，你是如何进行数据写入Redis队列的？ 数据写入的格式如果是JSON，你是如何进行处理</description></item></channel></rss>